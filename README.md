The project  uses Zero-Shot Predictions from OpenAi:
https://github.com/openai/CLIP

The project uses images from Sketchy Database dataset:
https://github.com/CDOTAD/SketchyDatabase?tab=readme-ov-file

The goal is to use Ploty Dash (https://dash.plotly.com/) to analyze the clip model on sketches.

assets: contains all images for every class, there are 10 images per class.

my_clip: Analyzes images from the assets folder using the CLIP model and stores the results in a CSV file named results.csv. It will overwrite the existing results.csv file every run.

my_dash: Creates a bar graph using Plotly Dash to visualize the number of correct and incorrect predictions for selected classes. Users can select a class from the drop-down bar. Images from the selected class are shown below, the green border symbolizes correct predictions, and the red symbolizes incorrect predictions. Below each image, the top 5 predictions are shown for the corresponding image from the CLIP model. Again the results.csv is used to get data for the bar graph, and the predictions shown for each image. 

my_fig: Creates a bar graph using Plotly Dash to visualize the number of correct and incorrect predictions for all classes. The data for this visualization is retrieved from the results.csv file, which was generated by the my_clip script.

results.csv: contains data from my_clip, showing the path and the top 5 predictions.

